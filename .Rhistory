plot.sociomatrix(initial, main = "initial", drawlines = FALSE)
abline(h = 1.5, v = 1.5, col ="red")
plot.sociomatrix(reordered, main = 'reordered', drawlines = FALSE)
par(mfrow = c(1,1))
}
reordering(path)
reordering = function(file, source_order = source_ordering, destination_order=destination_ordering){
edgelist = read.table(file, header = FALSE, sep =';')
names(edgelist) = c("source_nodes","destin_nodes","timestamp")
source_order = as.character(source_order)
destination_order = as.character(destination_order)
bipartite_adj = as.matrix(table(edgelist$source_nodes, edgelist$destin_nodes))
initial = bipartite_adj[,]
reordered = bipartite_adj[source_order, destination_order]
par(mfrow = c(1,2))
plot.sociomatrix(initial, main = "initial", drawlines = FALSE)
abline(h = 1.5, v = 1.5, col ="red", lty = 1)
plot.sociomatrix(reordered, main = 'reordered', drawlines = FALSE)
par(mfrow = c(1,1))
}
reordering(path)
reordering = function(file, source_order = source_ordering, destination_order=destination_ordering){
edgelist = read.table(file, header = FALSE, sep =';')
names(edgelist) = c("source_nodes","destin_nodes","timestamp")
source_order = as.character(source_order)
destination_order = as.character(destination_order)
bipartite_adj = as.matrix(table(edgelist$source_nodes, edgelist$destin_nodes))
initial = bipartite_adj[,]
reordered = bipartite_adj[source_order, destination_order]
par(mfrow = c(1,2))
plot.sociomatrix(initial, main = "initial", drawlines = FALSE)
abline(h = 1.5, v = 1.5, col ="red", lty = 3)
plot.sociomatrix(reordered, main = 'reordered', drawlines = FALSE)
par(mfrow = c(1,1))
}
reordering(path)
edge_freq = rbind(c(0,4,4,0,1),c(1,0,5,0,0),c(0,1,0,4,0),c(1,0,0,1,3))
edge_freq
k = seriation(edge_freq)
k = seriate(edge_freq)
k
print(k)
get_order(k,2)
get_order(k,2)
get_order(k,1)
get_order(k,2)
source_ordering = c(2,3,6,9,0,1,4,8,5,7)
destination_ordering = c(13,6,10,12,15,17,14,11,18,19)
path = "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelist.txt"
reordering(path)
reordering = function(file, source_order = source_ordering, destination_order=destination_ordering){
edgelist = read.table(file, header = FALSE, sep =';')
names(edgelist) = c("source_nodes","destin_nodes","timestamp")
source_order = as.character(source_order)
destination_order = as.character(destination_order)
bipartite_adj = as.matrix(table(edgelist$source_nodes, edgelist$destin_nodes))
initial = bipartite_adj[,]
reordered = bipartite_adj[source_order, destination_order]
par(mfrow = c(1,2))
plot.sociomatrix(initial, main = "initial", drawlines = FALSE)
abline(h = 1.5, v = 1.5, col ="red", lty = 3)
plot.sociomatrix(reordered, main = 'reordered', drawlines = FALSE)
par(mfrow = c(1,1))
}
source_ordering = c(2,3,6,9,0,1,4,8,5,7)
destination_ordering = c(13,16,10,12,15,17,14,11,18,19)
destination_ordering = c(13,16,10,12,15,17,14,11,18,19)
path = "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelist.txt"
reordering(path)
edge_freq = rbind(c(0,12,12),c(6,0,6))
k = seriate(edge_freq)
get_order(k,1)
get_order(k,2)
edge_freq = rbind(c(0,12),c(6,0))
k = seriate(edge_freq)
get_order(k,1)
get_order(k,2)
source_ordering = c(7, 9, 10, 11, 6, 8)
destination_ordering = c(0, 1, 4, 2, 3, 5)
path = "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/tmp.txt"
reordering(path)
min =0
nodearv = 1026577714
idx = sample(min:nodearv, 1000)
head(idx)
write.table(idx, "C:\\Users\\v-anleon\\Desktop\\Tartu_University\\Algorithmics2013\\project\\random_nodes_1000.txt")
write.table(idx, "C:\\Users\\v-anleon\\Desktop\\Tartu_University\\Algorithmics2013\\project\\random_nodes_1000.txt", col.names = FALSE, row.names = FALSE)
split(a, 4)
a = 0:99
split(a,4)
?split
split_fn(a, 5)
#libraries
library(igraph)
library(FNN)
library(seriation)
library(reshape)
library(gridExtra)
library(sna)
setwd("C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project")
reordering = function(file, source_order = source_ordering, destination_order=destination_ordering){
edgelist = read.table(file, header = FALSE, sep =';')
names(edgelist) = c("source_nodes","destin_nodes","timestamp")
source_order = as.character(source_order)
destination_order = as.character(destination_order)
bipartite_adj = as.matrix(table(edgelist$source_nodes, edgelist$destin_nodes))
initial = bipartite_adj[,]
reordered = bipartite_adj[source_order, destination_order]
par(mfrow = c(1,2))
plot.sociomatrix(initial, main = "initial", drawlines = FALSE)
abline(h = 1.5, v = 1.5, col ="red", lty = 3)
plot.sociomatrix(reordered, main = 'reordered', drawlines = FALSE)
par(mfrow = c(1,1))
}
pairwise_combination = function(v,p){
u = c()
for(i in 1:length(v)){
for(j in 1:length(p)){
u = rbind(u, c(v[i],p[j]))
}
}
return(u)
}
split_fn = function(x, groups){
groups = groups-1
g <- factor(round(groups * runif(groups * x)))
bins <- split(x, g)
return(bins)
}
split_fn(a, 5)
a = 0:99
b = 100:199
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
head(edgelist)
edges_total = nrow(edgelist)
deletions = 0.005*edges_total
deletions = round(0.005*edges_total,0)
set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
idx_to_delete
edgelist = edgelist[-idx_to_delete,]
0.1
prcnt_noise = 0.01
deletions = round(prcnt_noise*edges_total,0)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.01
#delete 0.5% of edges
deletions = round(prcnt_noise*edges_total,0)
deletions = round((prcnt_noise/2)*edges_total,0)
set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
additions = round((prcnt_noise/2)*edges_total,0)
source_idx_add = sample(a, additions)
source_idx_add
additions = round((prcnt_noise/2)*edges_total,0)
source_idx_add = sample(a, additions, replace = T)
destination_idx_add = sample(b, additions, replace = T)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = cbind(source_add,destination_add)
added_edges
added_edges = cbind(source_add,destination_add,1)
added_edges
edgelist = rbind.data.frame(edgelist,added_edges)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
head(added_edges)
head(edgelist)
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
head(edgelist)
g = graph.data.frame(edgelist, directed = FALSE)
plot(g, mark.groups=list(0:9),layout=layout.reingold.tilford)
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.01
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add 0.5%
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelist_noise_1pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_1pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
edges_total = nrow(edgelist)
prcnt_noise = 0.02
deletions = round((prcnt_noise/2)*edges_total,0)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_2pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
edges_total = nrow(edgelist)
prcnt_noise = 0.05
deletions = round((prcnt_noise/2)*edges_total,0)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_5pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
edgelist = edgelist[-which(duplicated(edgelist)==TRUE,]
edgelist = edgelist[-which(duplicated(edgelist==TRUE),]
length(which(duplicated(edgelist==TRUE))
)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.01
deletions = round((prcnt_noise/2)*edges_total,0)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_1pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.02
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
#set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_2pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.05
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
#set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_5pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.1
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
#set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_10pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.25
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
#set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_25pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.5
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
#set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_noise_50pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
head(edgelist)
prct1 = read.table("C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelists/edgelist_noise_1.txt", header = FALSE)
prct1 = read.table("C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelists/edgelist_noise_1pct.txt", header = FALSE)
head(prct1)
prct1 = read.table("C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelists/edgelist_noise_1pct.txt", header = FALSE, sep = ';')
head(prct1)
names(prct1) = c("source_nodes","destin_nodes","timestamp")
bipartite_adj = as.matrix(table(prct1$source_nodes, prct1$destin_nodes))
bipartite_adj
initial = bipartite_adj[,]
head(initial)
k = seriate(initial)
get_order(k,1)
source_order = get_order(k,1)
destination_order = get_order(k,2)
reordered = bipartite_adj[source_order, destination_order]
head(reordered)
reordered = as.data.frame(reordered)
head(reordered)
write.table(reordered, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project/edgelists/reodered_noise_1pct.txt", col.names =FALSE, row.names=FALSE)
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:999
b = 1000:1999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
edges_total = nrow(edgelist)
set.seed(round(runif(1, min=2, max = 200),0))
a = 0:499
b = 500:999
groups = 4
sources = split_fn(x=a, groups = 4)
destinations = split_fn(x =b,groups = 4)
edgelist = c()
for(i in 1:groups){
edgelist = rbind(edgelist, pairwise_combination(sources[[i]],destinations[[i]]))
}
edgelist = as.data.frame(edgelist)
head(edgelist)
edgelist = cbind.data.frame(edgelist,1)
#introducing noise
edges_total = nrow(edgelist)
prcnt_noise = 0.01
#delete 0.5% of edges
deletions = round((prcnt_noise/2)*edges_total,0)
#set.seed(6576)
idx_to_delete = sample(nrow(edgelist), deletions)
edgelist = edgelist[-idx_to_delete,]
#add noise
#random sample of existing source nodes
additions = round((prcnt_noise/2)*edges_total,0)
source_add = sample(a, additions, replace = T)
destination_add = sample(b, additions, replace = T)
added_edges = as.data.frame(cbind(source_add,destination_add,1))
names(added_edges) = names(edgelist)
edgelist = rbind.data.frame(edgelist,added_edges)
edgelist = edgelist[-which(duplicated(edgelist)==TRUE),]
write.table(edgelist, "C:/Users/v-anleon/Desktop/Tartu_University/Algorithmics2013/project_bins/data/edgelist_500_noise_1pct.txt", col.names= FALSE, row.names = FALSE, sep =';')
